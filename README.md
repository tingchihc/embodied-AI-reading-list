This repository offers a brief summary of essential papers and blogs on embodied AI, alongside a categorized collection of 3D scene representation, LLM agents papers and useful code repositories for starting your own project.

# Table of Contents  

Topic 1: <b>[Learning about 3D reconstruction and scene rendering](#nerf)</b>  
Topic 2: <b>[Learning about 3D scene representation](#3d-scene-rep)</b>  
Topic 3: <b>[Learning about LLM agents](#llm-agent)</b>  
Topic 4: <b>[Learning about Text-to-image/video](#t2iv)</b>  
Topic 5: <b>[Learning about Auto driving](#auto-drive)</b>  

<details>
  <summary><b>Topic 1: Learning about 3D reconstruction and scene rendering</b><a name="nerf"></a></summary>
  <ul>
    <li>Yuqi Zhang, et al. Efficient Large-scale Scene Representation with a Hybrid of High-resolution Grid and Plane Feature.<a href="https://arxiv.org/pdf/2303.03003">üìö</a> <a href="https://zyqz97.github.io/GP_NeRF/">üåç</a></li> arxiv.
  </ul>
</details>

<details>
  <summary><b>Topic 2: Learning about 3D scene representation</b><a name="3d-scene-rep"></a></summary>
  <ul>
    <li>Alexandros Delitzas, et al. SceneFun3D:  Fine-Grained Functionality and Affordance Understanding in 3D Scenes.<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Delitzas_SceneFun3D_Fine-Grained_Functionality_and_Affordance_Understanding_in_3D_Scenes_CVPR_2024_paper.pdf">üìö</a> CVPR, 2024.
    <li>Songyou Peng, et al. OpenScene: 3D Scene Understanding with Open Vocabularies. <a href="https://arxiv.org/pdf/2211.15654">üìö</a>. CVPR, 2023.
    <li>Yining Hong, et al. 3D-LLM: Injecting the 3D World into Large Language Models. <a href="https://arxiv.org/pdf/2307.12981">üìö</a>. NeurIPS, 2023.  
    <li>Yicong Hong, et al. Learning Navigational Visual Representations with Semantic Map Supervision. <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Learning_Navigational_Visual_Representations_with_Semantic_Map_Supervision_ICCV_2023_paper.pdf#:~:text=Inspired%20by%20the%20behavior%20that%20hu-mans%20naturally%20build">üìö</a>. ICCV, 2023.  
  </ul>
</details>



## LLM agents
<a name="llm-agent"></a>

- Tianhua Tao, et al. [CRYSTAL: Illuminating LLM Abilities on Language and Code](https://openreview.net/attachment?id=kWnlCVcp6o&name=pdf). COLM, 2024.
- Qingyun Wu, et al. [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversations](https://openreview.net/attachment?id=BAakY1hNKS&name=pdf). COLM, 2024.  
- Runsen Xu, et al. [PointLLM: Empowering Large Language Models to Understand Point Clouds](https://arxiv.org/pdf/2308.16911). ECCV, 2024.  

## Text to image/video
<a name="t2iv"></a>

- Abhay Zala, et al. [DiagrammerGPT: Generating Open-Domain, Open-Platform Diagrams via LLM Planning](https://openreview.net/attachment?id=NV8yRJRET1&name=pdf). COLM, 2024.
- Han Lin, et al. [VideoDirectorGPT: Consistent Multi-Scene Video Generation via LLM-Guided Planning](https://openreview.net/attachment?id=sKNIjS2brr&name=pdf), COLM, 2024.

## Auto driving
<a name="auto-drive"></a>

- Jiageng Mao, et al. [A Language Agent for Autonomous Driving](https://openreview.net/attachment?id=UPE6WYE8vg&name=pdf). COLM, 2024.  
